{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4S27MUk6eEa/HpMOMe5Xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FayCodes/AI-Assignment-Week-3/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values (convert range from 0-255 to 0-1)\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape data to fit CNN input format (28x28 images with 1 color channel)\n",
        "x_train = np.expand_dims(x_train, axis=-1)\n",
        "x_test = np.expand_dims(x_test, axis=-1)\n",
        "\n",
        "# Print dataset shape\n",
        "print(f\"Training data shape: {x_train.shape}, Labels shape: {y_train.shape}\")\n",
        "print(f\"Test data shape: {x_test.shape}, Labels shape: {y_test.shape}\")\n"
      ],
      "metadata": {
        "id": "HEITrZBdxIrb",
        "outputId": "434eb427-1f02-4b83-921b-82e8f7dd39b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Training data shape: (60000, 28, 28, 1), Labels shape: (60000,)\n",
            "Test data shape: (10000, 28, 28, 1), Labels shape: (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ethical Considerations in AI Models\n",
        "\n",
        "AI models, including those trained on datasets like MNIST for digit classification or Amazon Reviews for sentiment analysis, can unintentionally inherit biases from their training data. These biases can affect the fairness and accuracy of predictions, leading to skewed results that disproportionately favor certain groups or patterns.\n",
        "\n",
        "For example, in the MNIST dataset, if certain digits (like \"1\" or \"7\") appear more frequently than others, the model might become better at recognizing those digits while struggling with less common ones. Similarly, in Amazon Reviews sentiment analysis, biases can emerge if the dataset contains more reviews from a specific demographic or product category, leading to unfair sentiment predictions.\n",
        "\n",
        "To address these concerns, tools like TensorFlow Fairness Indicators can help analyze model performance across different subgroups, ensuring that predictions remain balanced and unbiased. Additionally, spaCy’s rule-based systems can refine text processing by filtering out biased language patterns, improving the fairness of NLP models.\n",
        "\n",
        "Ultimately, ethical AI development requires continuous monitoring, diverse training data, and fairness-aware evaluation techniques to ensure that models make equitable and reliable predictions."
      ],
      "metadata": {
        "id": "T7tvYmLG6BKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensorflow script with errors\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a simple model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(784,)),  # Incorrect input shape\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])  # Incorrect loss function\n",
        "\n",
        "# Generate random data (incorrect shape)\n",
        "x_train = tf.random.normal((60000, 28, 28))  # Should be flattened to (60000, 784)\n",
        "y_train = tf.random.uniform((60000,), maxval=10, dtype=tf.int32)\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)  # Will cause shape mismatch error\n"
      ],
      "metadata": {
        "id": "iMyzEzxT7pLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debugged code\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a corrected model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),  # Fix: Flatten layer to match MNIST input\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Correct loss function for classification\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generate correctly shaped random data\n",
        "x_train = tf.random.normal((60000, 28, 28))  # MNIST images are 28x28\n",
        "y_train = tf.random.uniform((60000,), maxval=10, dtype=tf.int32)  # Labels should be integers\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5)  # Now runs without shape mismatch errors\n"
      ],
      "metadata": {
        "id": "IwE1Qx9V7zOk",
        "outputId": "fb0c6a06-6baf-4112-edbe-6f09cdaf4ded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.1035 - loss: 2.5231\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1821 - loss: 2.2307\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2254 - loss: 2.1544\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.2877 - loss: 2.0303\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.3643 - loss: 1.8579\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7deda2758850>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}